# Summary Post
This will be my last blog post sadly :rage1: 

Fastai workbook progress:
| Notebook | Completed/Not Completed |
|-|-|
| Notebook00 | **Completed** |
| Notebook01 | **Completed** |
| Notebook02 | **Completed** |
| Notebook03 | **Completed** |
| Notebook04 | **Completed** |
| Notebook05 | **Completed** |
| Notebook06 | **Completed** |
| Notebook07 | **Completed** |
| Notebook08 | **Completed** |
| Notebook09 | **Completed** |
| Notebook10 | **Completed** |

I learnt many things in the short time I spent on progressing through Jeremy's videos and the provided notebooks. Heres just some of them:
1. Creating and training a basic model with fastai and other libraries like pytorch.
2. Processing and altering unique and already built datasets.
3. Uploading models to kaggle and competing in kaggle competitions.
4. Mathematical aspects integral to deep learning structures like gradient descent functions.
5. Understanding the weights and layers associated with models.
6. The ins and outs of binary splits and random forests.
7. Collarborative embedding in matrixes and model intepretation.
8. Embeddings and convolution and its importance in deep learning model strength.

I had fun in the short time spent learning this course. I would rate it ðŸ’¯. Thankyou to Professor Brian Lovell for providing access and Jeremy Howard for
designing a fun and interactive forum for deep learining.





